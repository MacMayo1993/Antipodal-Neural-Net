name: Generate Benchmark Artifacts

on:
  workflow_dispatch:  # Manual trigger
  push:
    branches:
      - main
    paths:
      - 'scripts/run_benchmark.py'
      - 'scripts/make_tables.py'
      - 'scripts/make_figures.py'

jobs:
  benchmark:
    name: Full Benchmark + Tables + Figures
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Set up Python 3.10
      uses: actions/setup-python@v4
      with:
        python-version: "3.10"

    - name: Cache pip packages
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install matplotlib pandas

    - name: Verify installation
      run: |
        python -c "import torch; print(f'PyTorch {torch.__version__}')"
        python -c "import numpy; print(f'NumPy {numpy.__version__}')"
        python -c "import matplotlib; print(f'Matplotlib {matplotlib.__version__}')"
        python -c "import pandas; print(f'Pandas {pandas.__version__}')"

    - name: Run quick smoke test
      run: |
        python quick_smoke_test.py

    - name: Run full benchmark
      run: |
        echo "Starting full benchmark (this takes ~30 minutes)..."
        python scripts/run_benchmark.py
        echo "Benchmark complete!"

    - name: Generate LaTeX tables
      run: |
        echo "Generating LaTeX tables..."
        python scripts/make_tables.py

    - name: Generate figures
      run: |
        echo "Generating publication figures..."
        python scripts/make_figures.py

    - name: Verify artifacts
      run: |
        ls -lh artifacts/
        ls -lh artifacts/figures/
        echo "=== metrics.csv preview ==="
        head -20 artifacts/metrics.csv
        echo "=== table_main.tex preview ==="
        head -40 artifacts/table_main.tex

    - name: Upload benchmark artifacts
      uses: actions/upload-artifact@v3
      with:
        name: benchmark-artifacts
        path: |
          artifacts/metrics.csv
          artifacts/table_main.tex
          artifacts/table_ablation.tex
          artifacts/table_generalization.tex
          artifacts/figures/*.png
        retention-days: 30

    - name: Create artifact summary
      run: |
        echo "## Benchmark Artifacts Generated" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Files Created:" >> $GITHUB_STEP_SUMMARY
        echo "- \`metrics.csv\`: Complete benchmark data" >> $GITHUB_STEP_SUMMARY
        echo "- \`table_main.tex\`: Main results table" >> $GITHUB_STEP_SUMMARY
        echo "- \`table_ablation.tex\`: Ablation study table" >> $GITHUB_STEP_SUMMARY
        echo "- \`table_generalization.tex\`: Generalization results" >> $GITHUB_STEP_SUMMARY
        echo "- \`figures/*.png\`: 3 publication figures" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Download:" >> $GITHUB_STEP_SUMMARY
        echo "Click 'Artifacts' at the top of this page to download \`benchmark-artifacts.zip\`" >> $GITHUB_STEP_SUMMARY
